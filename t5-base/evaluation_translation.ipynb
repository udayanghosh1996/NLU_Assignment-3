{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2981cf-ea5c-4e26-b866-bbb1d8717700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapull import pull_data\n",
    "from datasets import DatasetDict\n",
    "task = \"translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f96f813-7a67-413d-b145-c2bbce19a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_file_path = \"./train.en\"\n",
    "hindi_file_path = \"./train.hi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21c76c5-8ea5-48de-a50e-9817d302e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading English-Hindi Translation Data : \n",
      "Train-Test-Valiation Split : \n"
     ]
    }
   ],
   "source": [
    "dataset = pull_data(english_file_path, hindi_file_path,task)\n",
    "\n",
    "## Train-Test-Valiation Split \n",
    "print(\"Train-Test-Valiation Split : \")\n",
    "train_test_dataset = dataset.train_test_split(test_size=0.15)\n",
    "test_valid = train_test_dataset['test'].train_test_split(test_size=0.5)\n",
    "raw_datasets = DatasetDict({'train': train_test_dataset['train'],\n",
    "                            'test': test_valid['test'],\n",
    "                            'valid': test_valid['train']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcacda84-d48f-4583-a9bf-a2710bf7b046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 12750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1125\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7693077a-4237-428c-9f8f-2bea1889f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_list = [list(hi.values())[0] for hi in  raw_datasets['valid']['translation']][:10]\n",
    "gt_list = [list(hi.values())[1] for hi in  raw_datasets['valid']['translation']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a956cd-f0c5-4b3e-a4db-3aa1d5553288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We expect this number to rise further.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe7e5a2a-17da-4611-ab59-e2669c11d099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4439ac76-0b6e-4aff-b11f-04cd68fe4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, AutoTokenizer\n",
    "model_path = \"/home/jupyter/duplicates_detection/intl-duplicates/det_lat/test_folder/en-hi-translation-finetuned-14apr/checkpoint-76500\"\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Define the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c3eccc7-37ec-4aea-8273-47b3b847e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input text\n",
    "input_tokens = tokenizer.batch_encode_plus(input_text_list, max_length=512, truncation=True, return_tensors=\"pt\",padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabc1827-6820-4679-a807-fc07da6e1c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The police have arrested both the accused and they were presented before Court.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_tokens['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82553927-ba47-4baa-923f-4ceb4d791c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, AutoTokenizer\n",
    "\n",
    "def evaluate_model(model_path, input_text,ground_truth,task):\n",
    "    print(f\"{task.upper() } Evaluation : \")\n",
    "    \n",
    "    # Load the model checkpoint\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "    # Define the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_tokens = tokenizer.batch_encode_plus(input_text, max_length=512, truncation=True, return_tensors=\"pt\",padding=True)\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = model.generate(input_ids=input_tokens[\"input_ids\"], attention_mask=input_tokens[\"attention_mask\"],max_length= 128,early_stopping = True)\n",
    "\n",
    "    # Decode the generated output tokens\n",
    "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    pred_list = []\n",
    "    for inp,out,gt in zip(input_text,output_text,ground_truth) :\n",
    "        print('*'*100)\n",
    "        print()\n",
    "        print(f\"{task.upper() } Model input : {inp} \")\n",
    "        print(f\"{task.upper() } Model output : {out} \")\n",
    "        print(f\"Ground Truth : {gt} \")\n",
    "        print()\n",
    "        print('*'*100)\n",
    "        pred_list.append(out)\n",
    "        \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd17bdd-780f-4f21-929c-4abe08fd5afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSLATION Evaluation : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : With a very high number of COVID patients recovering every day, Indias steady trend of posting high level of daily recoveries continues.89,154 recoveries have been registered in the last 24 hours in the country\n",
      " \n",
      "TRANSLATION Model output : इस साल जून में कोरोना वायरस के अनुसार, देश में अब तक 7 से अधिक लोग ठीक हुए हैं, जबकि चीन के एक नए मरीज हैं, जो भारत में अब तक कुल कोरोना से ठीक हो चुके हैं। इसके साथ ही देश में अब तक कुल 29 लोगों की मौत हो गई है। वहीं भारतीय दंड संहिता,118,51,51,118,51,51,118,51,51,118,51,51,118,51,114 लाख से अब तक देश में अब तक देश में अब तक देश \n",
      "Ground Truth : हर दिन ठीक होने वाले कोविड रोगियों की अधिक संख्या के साथ ही भारत में रोजाना अधिक संख्या में लगातार रिकवरी  भी जारी है\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : The police have arrested both the accused and they were presented before Court.\n",
      " \n",
      "TRANSLATION Model output : पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ मामला दर्ज कर जांच शुरू कर दी है। पुलिस ने आरोपी के खिलाफ हत्या का के आधार परिजनों को अदालत \n",
      "Ground Truth : पुलिस ने दोनों आरोपियों से पूछताछ के लिए उनको अदालत में पेश कर रिमांड पर ले लिया है।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : We expect this number to rise further.\n",
      " \n",
      "TRANSLATION Model output : हम इस बारे में कोई नहीं कह सकते हैं कि यह काफी नहीं हैं। हम काफी कुछ भी नहीं हैं। हम चाहेंगे कि कोई बात नहीं कर सकता। हम काफी कुछ नहीं हैं। हम इसे भी कुछ भी नहीं कर सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ नहीं कह सकते हैं। हम इसे भी कुछ भी कहना चाहता था. हम किसी को भी वो \n",
      "Ground Truth : साथ ही उम्मीद जताई कि यह नंबर और ज्यादा बढ़ जाएगा।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : The Home Ministry has sought a report from the Delhi Police.\n",
      " \n",
      "TRANSLATION Model output : दिल्ली पुलिस ने इस मामले में जांच के लिए एसपीओ के सरकारी अस्पताल में केस दर्ज किया है। मामले में जांच की मांग की है। मामले में जांच की जा रही है। मामले में जांच की मांग की है। मामले में जांच की जा रही है। मामले में जांच की मांग की है। मामले में जांच की है। मामले में जांच की मांग की है। मामले में जांच की है। मामले में जांच की मांग की है। मामले में जांच की मांग की है। मामले में जांच की जा रही है कि मामले की जांच की मांग की है। मामले \n",
      "Ground Truth : गृह मंत्रालय ने दिल्ली पुलिस से मांगी रिपोर्ट\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : Parliament remained almost dysfunctional for the third consecutive day with BJP members persistently creating pandemonium over the undemocratic appointment of Lokayukta in Gujarat, leading to repeated adjournments of both Houses.\n",
      " \n",
      "TRANSLATION Model output : भाजपा के नेतृत्व वाली एनडीए के अध्यक्ष कन्हैया कुमार द्वारा आयोजित किये गये कदमों के लिए वोट किए गए कदमों के लिए वोटों के लिए वोटों के लिए वोटों के लिए वोटों के लिए वोट देने के लिए वोट किए गए जहां से ही आईएएस के उम्मीदवारों की मांग के बाद सत्ता में से बीजेपी के उम्मीदवार के रूप में से एक है। भाजपा ने राज्य के स्थगन के लिए पार्टी के एक सर्वेक्षण में से एक याचिकाओं के लिए पार्टी की आलोचना की। भाजपा ने राज्यसभा की बैठक में पार्टी के अध्यक्ष के रूप में \n",
      "Ground Truth : गुजरात में लोकायुक्त की नियुक्ति के मुद्दे पर भाजपा सदस्यों का संसद में आज भी हंगामा जारी रहा, जिसके चलते लोकसभा की बैठक एक बार के स्थगन के बाद और राज्यसभा की कार्यवाही दो बार के स्थगन के बाद पूरे दिन के लिए स्थगित कर दी गई।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : The film also stars Tabu, Aditi Rao Hydari, Lara Dutta and Rahul Bhatt.\n",
      " \n",
      "TRANSLATION Model output : फिल्म में उनके साथ फिल्म नसीरुक्षेत्र, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर, करीना कपूर खान, कर \n",
      "Ground Truth : 'फितूर' में अदिति राव हैदरी, लारा दत्ता और राहुल भट्ट भी प्रमुख भूमिका में हैं।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : I myself feel that this public clamour would never have attained these dimensions if we had been bold enough to give a correct lead by making known our opinion publicly to the people.\n",
      " \n",
      "TRANSLATION Model output : मैं इस बात का पता लगा कि मैं इस बात का मतलब है कि हम सभी को इस तरह से इस तरह से देख सकते हैं कि हम इस बात का पता लगाने के लिए हम इस बात का अवसर प्रदान करता है कि हम इस बात पर विचार करने के लिए पिछले कुछ समय से इस तरह से इस तरह से इस तरह की ओर से इस तरह की जगह मैं इस बात से देख रहे हैं कि हम इस बात पर इस तरह की संख्या बढ़ सकें। मैं इस बात से इस बात का पता लगाने के लिए हम इस बात पर इस तरह की जगह मैं इस बात का सामना करने के लिए हम इस बात का सामना करने के लिए हम \n",
      "Ground Truth : मुझे स्वयं ऐसा लगाता है कि अगर इस विषय में हमने अपनी राय लोगों के सामने खुले रूप में रखकर उनका सही नेतृत्व करने का साहस होता, तो लोगों का यह शोरगुल इस हद तक कभी न बढ पाता।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : I have lost a valued friend, PM Modi mourns Arun Jaitleys death\n",
      " \n",
      "TRANSLATION Model output : राष्ट्रपति रामनाथ कोविंद ने राष्ट्रपति भवन में राष्ट्रपति भवन का स्वागत किया है राष्ट्रपति रामनाथ कोविंद के साथ एक बार फिर शुरू किया है। राष्ट्रपति भवन में, राष्ट्रपति भवन में नजर आए थे। राष्ट्रपति भवन में राष्ट्रपति भवन राष्ट्रपति भवन में राष्ट्रपति रामनाथ कोविंद ने किया सरेंडर राष्ट्रपति भवन में कहा, ‘‘अविंद ने किया था राष्ट्रपति भवन में दो सांसदों को बधाई देता हूं। राष्ट्रपति भवन में एक बड़ा बयान जारी किया राष्ट्रपति भवन में शामिल होने की अनुमति दी। राष्ट्रपति भवन \n",
      "Ground Truth : अरुण जेटली के निधन पर पीएम मोदी ने किया भावुक ट्वीट, कहा- मैंने अपना मूल्यवान दोस्त खो दिया\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : Turn it on.\n",
      " \n",
      "TRANSLATION Model output : यह प्रक्रिया लगातार करते रहें। यहां तक कि कोई भी परीक्षा नहीं है। ये वीडियो. बस एक ही है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. यह सब कुछ नहीं है. ये वीडियो. ये है. ये है. यह \n",
      "Ground Truth : इसको आप ऑन कर दें।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "\n",
      "TRANSLATION Model input : Printing and stationary means the official work of printing and writing materials or other office supplies.\n",
      " \n",
      "TRANSLATION Model output : यह एक महत्वपूर्ण वैश्विक चुनौती है जोपाकिस्तान और मौजूदा रूप से सहमति है और इसे सहमति के रूप में विकसित हो सकता है। यह एक दूसरे के रूप में आपूर्ति सुनिश्चित करने के लिए एक दूसरे को प्रभावित करता है। यह एक दूसरे को प्रभावित करता है। यह एक दूसरे को प्रभावित करता है। यह एक दूसरे के रूप में एक-दूसरे के रूप में एक-दूसरे के रूप में एक है। यह एक दूसरे को प्रभावित करता है। यह एक दूसरे को प्रभावित करता है। यह एक दूसरे के रूप में एक-दूसरे के रूप में एक दूसरे को प्रभावित करता है, \n",
      "Ground Truth : मुद्रण तथा लेखन-सामग्री का अर्थ होता है, कार्यालय संबंधी मुद्रण कार्य और लेखन सामग्री या अन्य कार्यालयी आपूर्ति वस्तुएँ।\n",
      " \n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "generated_text = evaluate_model(model_path,input_text_list,gt_list,task)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446728e-85cd-41b1-9ea3-2ec08b8c90e7",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79a6ed1-955b-44a0-b9ba-9055bd0c5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate import bleu_score\n",
    "import nltk\n",
    "from rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf4a57f6-9adc-4e61-bf99-0af4b8f103b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(actual, generated):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    actual_tokenized = [nltk.word_tokenize(group) for group in actual]\n",
    "    generated_tokenized = [nltk.word_tokenize(gen) for gen in generated]\n",
    "    \n",
    "    score = corpus_bleu(actual_tokenized, generated_tokenized, smoothing_function=smoothie)\n",
    "    return score\n",
    "\n",
    "def calculate_rouge_scores(actual, generated):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated, actual)\n",
    "    return scores\n",
    "\n",
    "def calculate_cider_scores(actual, generated):\n",
    "    act_dict = {idx: [line] for idx, line in enumerate(actual)}\n",
    "    gen_dict = {idx: [line] for idx, line in enumerate(generated)}\n",
    "    cider = Cider()\n",
    "    (score, scores) = cider.compute_score(act_dict, gen_dict)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8386429b-2258-4f1b-bf1f-3a421166fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006194463600572004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu_scores(gt_list, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e560f894-8fd1-44cf-b8ca-0197cb34e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.38095238095238093,\n",
       "   'p': 0.18604651162790697,\n",
       "   'f': 0.24999999559082037},\n",
       "  'rouge-2': {'r': 0.09090909090909091,\n",
       "   'p': 0.037037037037037035,\n",
       "   'f': 0.05263157483379533},\n",
       "  'rouge-l': {'r': 0.23809523809523808,\n",
       "   'p': 0.11627906976744186,\n",
       "   'f': 0.15624999559082045}},\n",
       " {'rouge-1': {'r': 0.3333333333333333,\n",
       "   'p': 0.3333333333333333,\n",
       "   'f': 0.3333333283333334},\n",
       "  'rouge-2': {'r': 0.058823529411764705, 'p': 0.05, 'f': 0.05405404908692522},\n",
       "  'rouge-l': {'r': 0.2777777777777778,\n",
       "   'p': 0.2777777777777778,\n",
       "   'f': 0.2777777727777779}},\n",
       " {'rouge-1': {'r': 0.18181818181818182,\n",
       "   'p': 0.07692307692307693,\n",
       "   'f': 0.10810810392987599},\n",
       "  'rouge-2': {'r': 0.1, 'p': 0.025, 'f': 0.03999999680000026},\n",
       "  'rouge-l': {'r': 0.18181818181818182,\n",
       "   'p': 0.07692307692307693,\n",
       "   'f': 0.10810810392987599}},\n",
       " {'rouge-1': {'r': 0.375, 'p': 0.13636363636363635, 'f': 0.19999999608888894},\n",
       "  'rouge-2': {'r': 0.14285714285714285,\n",
       "   'p': 0.03333333333333333,\n",
       "   'f': 0.054054050986121434},\n",
       "  'rouge-l': {'r': 0.25, 'p': 0.09090909090909091, 'f': 0.13333332942222234}},\n",
       " {'rouge-1': {'r': 0.2777777777777778,\n",
       "   'p': 0.22727272727272727,\n",
       "   'f': 0.24999999505000006},\n",
       "  'rouge-2': {'r': 0.14285714285714285,\n",
       "   'p': 0.08955223880597014,\n",
       "   'f': 0.11009173838229125},\n",
       "  'rouge-l': {'r': 0.16666666666666666,\n",
       "   'p': 0.13636363636363635,\n",
       "   'f': 0.14999999505000017}},\n",
       " {'rouge-1': {'r': 0.07142857142857142, 'p': 0.1, 'f': 0.08333332847222251},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.07142857142857142, 'p': 0.1, 'f': 0.08333332847222251}},\n",
       " {'rouge-1': {'r': 0.17142857142857143,\n",
       "   'p': 0.16216216216216217,\n",
       "   'f': 0.16666666167052485},\n",
       "  'rouge-2': {'r': 0.02631578947368421,\n",
       "   'p': 0.018867924528301886,\n",
       "   'f': 0.021978017113876213},\n",
       "  'rouge-l': {'r': 0.17142857142857143,\n",
       "   'p': 0.16216216216216217,\n",
       "   'f': 0.16666666167052485}},\n",
       " {'rouge-1': {'r': 0.16666666666666666,\n",
       "   'p': 0.07692307692307693,\n",
       "   'f': 0.10526315357340738},\n",
       "  'rouge-2': {'r': 0.058823529411764705,\n",
       "   'p': 0.01818181818181818,\n",
       "   'f': 0.027777774170525165},\n",
       "  'rouge-l': {'r': 0.16666666666666666,\n",
       "   'p': 0.07692307692307693,\n",
       "   'f': 0.10526315357340738}},\n",
       " {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       " {'rouge-1': {'r': 0.16666666666666666,\n",
       "   'p': 0.10344827586206896,\n",
       "   'f': 0.12765956974196485},\n",
       "  'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "  'rouge-l': {'r': 0.1111111111111111,\n",
       "   'p': 0.06896551724137931,\n",
       "   'f': 0.08510637825260325}}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_rouge_scores(gt_list, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb7979b2-73eb-4d60-ad46-7a7b22c736f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.819146274310125e-13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cider_scores(gt_list, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a4c0c-8724-488e-8d1b-1d186bd8d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
